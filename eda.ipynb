{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import pathlib\n",
    "import streamlit as st\n",
    "\n",
    "### Param\n",
    "DATA_URL = \"https://github.com/owid/covid-19-data/raw/master/public/data/owid-covid-data.csv\"\n",
    "ISO_TO_LONLAT_URL = \"https://gist.githubusercontent.com/cpl/3dc2d19137588d9ae202d67233715478/raw/3d801e76e1ec3e6bf93dd7a87b7f2ce8afb0d5de/countries_codes_and_coordinates.csv\"\n",
    "LOCATION_COLUMN = 'location'\n",
    "THRESHOLD_FOR_CASES_PER_MILLION = 10000 # Some countries probably ofer no data. This is the threshold to filter those out. Also, to keep data lean, we drop a lot of countries.\n",
    "\n",
    "# HACK This only works when we've installed streamlit with pipenv, so the\n",
    "# permissions during install are the same as the running process\n",
    "STREAMLIT_STATIC_PATH = pathlib.Path(st.__path__[0]) / 'static'\n",
    "# We create a downloads directory within the streamlit static asset directory\n",
    "# and we write output files to it\n",
    "DOWNLOADS_PATH = (STREAMLIT_STATIC_PATH / \"downloads\")\n",
    "if not DOWNLOADS_PATH.is_dir():\n",
    "    DOWNLOADS_PATH.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Param\n",
    "DATA_URL = \"https://github.com/owid/covid-19-data/raw/master/public/data/owid-covid-data.csv\"\n",
    "ISO_TO_LONLAT_URL = \"https://gist.githubusercontent.com/cpl/3dc2d19137588d9ae202d67233715478/raw/3d801e76e1ec3e6bf93dd7a87b7f2ce8afb0d5de/countries_codes_and_coordinates.csv\"\n",
    "LOCATION_COLUMN = 'location'\n",
    "THRESHOLD_FOR_CASES_PER_MILLION = 10000 # Some countries probably ofer no data. This is the threshold to filter those out. Also, to keep data lean, we drop a lot of countries.\n",
    "\n",
    "# HACK This only works when we've installed streamlit with pipenv, so the\n",
    "# permissions during install are the same as the running process\n",
    "STREAMLIT_STATIC_PATH = pathlib.Path(st.__path__[0]) / 'static'\n",
    "# We create a downloads directory within the streamlit static asset directory\n",
    "# and we write output files to it\n",
    "DOWNLOADS_PATH = (STREAMLIT_STATIC_PATH / \"downloads\")\n",
    "if not DOWNLOADS_PATH.is_dir():\n",
    "    DOWNLOADS_PATH.mkdir()\n",
    "\n",
    "### Start of Webapp:\n",
    "# Get Data:\n",
    "def load_data():\n",
    "    data = pd.read_csv(DATA_URL)\n",
    "    long_lat_map = pd.read_csv(ISO_TO_LONLAT_URL, engine='python', sep=',', skipinitialspace=True)[['Alpha-3 code','Latitude (average)', 'Longitude (average)']]\n",
    "    long_lat_map = long_lat_map.rename(columns={\"Latitude (average)\": \"lat\", \"Longitude (average)\": \"lon\"})\n",
    "    data = data.merge(long_lat_map, how = 'inner', left_on = 'iso_code', right_on = 'Alpha-3 code').drop(columns = 'iso_code')\n",
    "    data.to_csv(str(DOWNLOADS_PATH / \"data.csv\"), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-03-02 23:22:02.157 WARNING root: \n  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n  command:\n\n    streamlit run C:\\Users\\vince\\anaconda3\\envs\\WET - covid dashboard\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<streamlit.delta_generator.DeltaGenerator at 0x1ab81c51d90>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Load data:\n",
    "data_load_state = st.text('Loading data')\n",
    "# Create a text element and let the reader know the data is loading.\n",
    "load_data()\n",
    "data = pd.read_csv(str(DOWNLOADS_PATH / \"data.csv\"), usecols = ['location', 'total_cases_per_million', 'total_deaths_per_million', 'total_tests_per_thousand']).drop_duplicates()\n",
    "data = data[data['total_cases_per_million']>THRESHOLD_FOR_CASES_PER_MILLION].dropna()\n",
    "data = data.pivot_table(index=['location'], values=['total_cases_per_million', 'total_deaths_per_million', 'total_tests_per_thousand'])\n",
    "data_load_state.text(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On a map:\n",
    "data = pd.read_csv(str(DOWNLOADS_PATH / \"data.csv\"), usecols = ['lon', 'lat', 'total_cases_per_million', 'total_deaths_per_million', 'total_tests_per_thousand']).drop_duplicates()\n",
    "data = data[data['total_cases_per_million']>THRESHOLD_FOR_CASES_PER_MILLION].dropna()\n",
    "data = data.pivot_table(index=['lon', 'lat'], values=['total_cases_per_million', 'total_deaths_per_million', 'total_tests_per_thousand']).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      lon      lat  total_cases_per_million  total_deaths_per_million  \\\n",
       "0  -102.0  23.0000             13284.276111               1157.056347   \n",
       "1   -97.0  38.0000             39500.426078                828.924570   \n",
       "2   -95.0  60.0000             15592.998444                421.138698   \n",
       "3   -84.0  10.0000             27209.258433                349.696111   \n",
       "4   -80.0   9.0000             39110.188687                712.508545   \n",
       "..    ...      ...                      ...                       ...   \n",
       "63   54.0  24.0000             21525.446581                 68.993372   \n",
       "64   68.0  48.0000             11893.973824                155.882446   \n",
       "65   73.0   3.2500             22973.789232                 77.961616   \n",
       "66  100.0  60.0000             19772.681529                362.636198   \n",
       "67  103.8   1.3667             10134.866222                  4.957000   \n",
       "\n",
       "    total_tests_per_thousand  \n",
       "0                  31.819042  \n",
       "1                 526.359243  \n",
       "2                 387.506238  \n",
       "3                  70.512187  \n",
       "4                 193.945172  \n",
       "..                       ...  \n",
       "63               1975.469784  \n",
       "64                332.388365  \n",
       "65                467.852414  \n",
       "66                591.005554  \n",
       "67               1081.234889  \n",
       "\n",
       "[68 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lon</th>\n      <th>lat</th>\n      <th>total_cases_per_million</th>\n      <th>total_deaths_per_million</th>\n      <th>total_tests_per_thousand</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-102.0</td>\n      <td>23.0000</td>\n      <td>13284.276111</td>\n      <td>1157.056347</td>\n      <td>31.819042</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-97.0</td>\n      <td>38.0000</td>\n      <td>39500.426078</td>\n      <td>828.924570</td>\n      <td>526.359243</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-95.0</td>\n      <td>60.0000</td>\n      <td>15592.998444</td>\n      <td>421.138698</td>\n      <td>387.506238</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-84.0</td>\n      <td>10.0000</td>\n      <td>27209.258433</td>\n      <td>349.696111</td>\n      <td>70.512187</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-80.0</td>\n      <td>9.0000</td>\n      <td>39110.188687</td>\n      <td>712.508545</td>\n      <td>193.945172</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>54.0</td>\n      <td>24.0000</td>\n      <td>21525.446581</td>\n      <td>68.993372</td>\n      <td>1975.469784</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>68.0</td>\n      <td>48.0000</td>\n      <td>11893.973824</td>\n      <td>155.882446</td>\n      <td>332.388365</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>73.0</td>\n      <td>3.2500</td>\n      <td>22973.789232</td>\n      <td>77.961616</td>\n      <td>467.852414</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>100.0</td>\n      <td>60.0000</td>\n      <td>19772.681529</td>\n      <td>362.636198</td>\n      <td>591.005554</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>103.8</td>\n      <td>1.3667</td>\n      <td>10134.866222</td>\n      <td>4.957000</td>\n      <td>1081.234889</td>\n    </tr>\n  </tbody>\n</table>\n<p>68 rows Ã— 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'DOWNLOADS_PATH' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-aa0a9119888d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDOWNLOADS_PATH\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m\"data.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'lon'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lat'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'total_cases_per_million'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'total_deaths_per_million'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'total_tests_per_thousand'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'total_cases_per_million'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mTHRESHOLD_FOR_CASES_PER_MILLION\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lon'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'total_cases_per_million'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'total_deaths_per_million'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'total_tests_per_thousand'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DOWNLOADS_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(str(DOWNLOADS_PATH / \"data.csv\"), usecols = ['lon', 'lat', 'total_cases_per_million', 'total_deaths_per_million', 'total_tests_per_thousand']).drop_duplicates()\n",
    "data = data[data['total_cases_per_million']>THRESHOLD_FOR_CASES_PER_MILLION].dropna()\n",
    "data = data.pivot_table(index=['lon', 'lat'], values=['total_cases_per_million', 'total_deaths_per_million', 'total_tests_per_thousand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['iso_code', 'continent', 'location', 'date', 'total_cases', 'new_cases',\n",
       "       'new_cases_smoothed', 'total_deaths', 'new_deaths',\n",
       "       'new_deaths_smoothed', 'total_cases_per_million',\n",
       "       'new_cases_per_million', 'new_cases_smoothed_per_million',\n",
       "       'total_deaths_per_million', 'new_deaths_per_million',\n",
       "       'new_deaths_smoothed_per_million', 'reproduction_rate', 'icu_patients',\n",
       "       'icu_patients_per_million', 'hosp_patients',\n",
       "       'hosp_patients_per_million', 'weekly_icu_admissions',\n",
       "       'weekly_icu_admissions_per_million', 'weekly_hosp_admissions',\n",
       "       'weekly_hosp_admissions_per_million', 'new_tests', 'total_tests',\n",
       "       'total_tests_per_thousand', 'new_tests_per_thousand',\n",
       "       'new_tests_smoothed', 'new_tests_smoothed_per_thousand',\n",
       "       'positive_rate', 'tests_per_case', 'tests_units', 'total_vaccinations',\n",
       "       'people_vaccinated', 'people_fully_vaccinated', 'new_vaccinations',\n",
       "       'new_vaccinations_smoothed', 'total_vaccinations_per_hundred',\n",
       "       'people_vaccinated_per_hundred', 'people_fully_vaccinated_per_hundred',\n",
       "       'new_vaccinations_smoothed_per_million', 'stringency_index',\n",
       "       'population', 'population_density', 'median_age', 'aged_65_older',\n",
       "       'aged_70_older', 'gdp_per_capita', 'extreme_poverty',\n",
       "       'cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers',\n",
       "       'male_smokers', 'handwashing_facilities', 'hospital_beds_per_thousand',\n",
       "       'life_expectancy', 'human_development_index'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "conf_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}